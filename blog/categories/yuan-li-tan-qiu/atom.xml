<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 原理探求 | 死亡的飞翔]]></title>
  <link href="http://dahakawang.github.com/blog/categories/yuan-li-tan-qiu/atom.xml" rel="self"/>
  <link href="http://dahakawang.github.com/"/>
  <updated>2013-03-12T20:31:11+08:00</updated>
  <id>http://dahakawang.github.com/</id>
  <author>
    <name><![CDATA[王凯强]]></name>
    <email><![CDATA[DevilDavidWang@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[【Ruby】require背后的故事]]></title>
    <link href="http://dahakawang.github.com/blog/2013/03/12/ruby-story-behind-require/"/>
    <updated>2013-03-12T14:39:00+08:00</updated>
    <id>http://dahakawang.github.com/blog/2013/03/12/ruby-story-behind-require</id>
    <content type="html"><![CDATA[<p>接触ruby有一段时间了，说起来自己和这门语言倒挺有缘。学生时代的时候，曾经沉迷于一款叫做RPG Maker的软件。当时和朋友以班上的同学为原型写了一部武侠剧，并计划用RPG Maker制作成游戏，乐此不疲。这个RPG Maker在内部使用了一门脚本语言来描述其游戏逻辑，这门语言便是Ruby。于是乎为了修改游戏框架、拓展引擎原有特性，自己花了不少功夫学习Ruby。可惜最后，由于高考临近，Ruby随着RPG Maker一块儿，淹没在了记忆的深处。</p>

<!-- more -->

<p>最近突然间有了兴趣，又把Ruby拿出来看看，却发觉这五六年间，Ruby语言的变化之大，是我难以预期的。无论是语言特性本身，还是周边的开发工具、程序库，都较之前有了较大的发展，于是重温变成了重新学习。</p>

<p>既然是学习，光说不练可不行，于是乎又一边开始学习起了Ruby on Rails来，希望能够学以致用。RoR在Ruby社区内可是有着响当当的名号，可以说Ruby之所以名声大噪，很大程度上都是由于RoR的功劳。RoR是一个纯粹的开源软件，它凝聚了世界上最优秀Ruby程序员的勤劳和天分。而我自己，也由于对RoR的研读，了解到了不少Ruby的精妙之处。喟叹之际，便也想对其抽丝剥茧，习其精髓，并记录于博客之中，以飨诸位同好。 Y(^_^)Y</p>

<h2 id="require">require到底干了什么？</h2>

<p>第一次看到require语句的时候，立刻有一种似曾相识的感觉。作为一名C语言起家的技术人，我看到了include的影子。从开发者的角度来说，这两条指令完成了相似的工作：告诉编译器我们想要引用其它地方的代码。但是，仔细思考和实验过后，却不难发觉，这两条指令在实现层面上乃是千差万别。</p>

<p>当我们include一个头文件的时候发生了什么？答案是编译器找到对应的头文件，并将其原地展开。通过对头文件中代码的解析，编译器知道了我们要引用的代码的声明（Declaration）。所谓声明，即是指编译器知道将要引用的代码到底长成什么样，而并不知道代码具体是什么（Definition）。而为了让我们的代码真正地用上所引用的代码，我们需要在链接的时候，向linker指明引用库的地址。而这个所谓的引用库，才包含了我们欲引用代码的具体定义。</p>

<p>反观require呢？当我们require某个外部代码的时候，我们实际上是告诉编译器寻找对应的rb文件。这个rb文件中有什么？答案是，引用代码的具体定义。这时候require和include有何区别的答案便呼之欲出了：由于Ruby没有传统意义上的链接过程，我们require实际上是载入代码的实现/定义；而对于C编译器来说，include只不过是告诉编译器代码长啥样，这使得编译器能够生成＂调用代码＂，而＂实现代码＂则是在链接阶段予以提供的。</p>

<h2 id="require-1">require的实现</h2>

<p>按照官方解释，require将会在Ruby的LOAD_PATH中查找对应文件并将其载入。好奇心促使我跟踪了require的执行过程，却发觉require并没有调用系统默认的Kernel#require，而是调用到了位于custom_require.rb中的Kernel#require函数之中。</p>

<p>而恰巧的是，这个文件是属于RubyGem的一部分。到目前为止，我们还能够理解发生了什么：RubyGem用自己的require替代了系统默认的版本，并藉此实现了它自己的逻辑。</p>

<p>可是这样理解后的问题接踵而来，首当其冲的问题便是，明明没有人引用RubyGem，那么这个文件是谁通过怎样的方式载入的呢？再则，我们开启irb，这时候理当没有任何Gem被载入，可是发觉Gem这个模块已经被定义了是怎么回事呢？</p>

<p>啊，一定有谁在我们的代码执行前就载入了RubyGem！我在RubyGem的代码中添加了打印函数调用栈的逻辑，然后运行一个空的Ruby脚本，看到了如下的现象：</p>

<pre><code>david@david-K40IN:~/Desktop/root$ ruby -e ''
/home/david/.rvm/rubies/ruby-1.9.3-p362/lib/ruby/site_ruby/1.9.1/rubygems.rb:1282:in `require'
/home/david/.rvm/rubies/ruby-1.9.3-p362/lib/ruby/site_ruby/1.9.1/rubygems.rb:1282:in `&lt;top (required)&gt;'
 &lt;internal:gem_prelude&gt;:1:in `require'
&lt;internal:gem_prelude&gt;:1:in `&lt;compiled&gt;'
</code></pre>

<p>可以观察到是一个叫做gem_prelude的文件载入了RubyGem。这个文件是什么？前面的internal似乎显示了它不一样的地位。我搜遍Ruby的目录，也没有找到这么一个文件，却只是在Ruby的源码目录中找到了它的身影。</p>

<p>原来，这个文件是编译Ruby时自动生成的（这里仅讨论Ruby较新的版本(1.9.x)，实现代码<a href="https://github.com/ruby/ruby/blob/trunk/tool/compile_prelude.rb">见此</a>)，它的内容只有一句话，那便是<code>require 'RubyGem' if defined?(Gem)</code>。其中Gem符号是在ruby.c里直接定义的（Hardcoded），如果你要取消该特性，编译Ruby的时候需要指明<code>--disable-gems</code>选项。</p>

<p>现在，问题的答案很明朗了。由于RubyGem使用地十分广泛，以至于Ruby开发团队决定予以其直接支持，这便是为什么我们总是发觉RubyGem被载入的原因了。这也同时更好地解释了，明明也是一个Gem，为什么RubyGem没有和其他Gem放到一块儿，并遵循Gem名加上版本号的命名方式。</p>

<h2 id="rubygem---">RubyGem - 将宝石打包</h2>

<p>咱们再来谈谈Ruby的包管理机制。这里的基本思路十分简单，Ruby本身载入某个代码只会在LOAD_PATH里寻找，如果我们定义＂使用某个Gem＂为将Gem所在路径添加到Ruby的LOAD_PATH里，这样当我们使用了某个Gem后，我们便能够载入这个Gem的代码了。其次，我们在包的根目录下放上某个包含诸如作者、主页、依赖的库等等信息的文件，这便有了Gem的元数据信息。最后，我们把Gem的根目录命名为Gem名加版本号，这样多版本的管理机制也就有了。于是乎，整个Gem的工作机制便呼之欲出了。</p>

<p>按照惯例，我们一般是用require ‘arel’的方式来载入Gem代码。可是，根据require函数定义，我们实际上需要将类似’gems/arel-3.0.2/arel’的参数传给require才能达到我们的目的。为什么简单的require ‘arel’能行呢？因为我们在此之前使用了gem ‘arel’ 语句，是它按照之前提到的规律找到了arel库某个版本的位置，并将它加入到LOAD_PATH里，这才使我们能够简单地require一个Gem库。</p>

<p>不过，正如上一节指出的，在新版本的Ruby里，Kernel#require早已自动被RubyGem里的同名函数覆盖了。因此，在新版本的Ruby里，我们连gem语句都不需要，可以直接require了（老版本则需要我们显式调用require ‘rubygem’才行）。不过，若是你需要明确的指定使用某一版本的Gem（Gem ‘arel’, ‘＞=3.0.0’），还是需要显示地调用gem方法。</p>

<p>RubyGem这个库具有两面性，上面的讨论仅是从Gem的使用者角度展开的。而RubyGem同时也给予了Gem库开发者以大量支持，但是我在这里不会讨论。</p>

<h2 id="bundler">Bundler</h2>

<p>好的，终于谈到它了，它是我最喜欢的一个工具。我在Linux下开发时间虽然不长，但是痛苦程度应该比起经验丰富的开发者也不遑多让。原因在于传统的Linux开发相当复杂，除了软件系统本身的复杂性外，还得受错综复杂的各种依赖关系所累。常常是一个程序还没开始编译，就得先安装个一天的各种依赖库再说。</p>

<p>但是，这个令我十分头痛的问题却被Bundler解决了，而且解决地十分漂亮。你的软件需要什么依赖库，具体依赖啥版本，你写成一个Gemfile清单来看。我check out你的代码后，啥也不管，简单地bundle install，开发环境就搭建好了，各种依赖库也到位了，好不痛快！</p>

<p>bundle install指令致力于确保Gem所有依赖库均被安装到本机，但它并不保证列在Gemfile里的依赖库在运行时被载入。为了让我们的程序使用上这些库，我们需要在运行时调用Bundler.setup，该方法将列举在Gemfile里的所有Gem被添加到LOAD_PATH中去。因此，Bundler.setup的行为类似于gem方法，用于帮助我们将特定版本的Gem载入到LOAD_PATH。只不过Bundler提供了更为高级的机制，使得我们能够在Gemfile里集中地管理所有依赖，并且省去了一一添加依赖的繁琐过程。</p>

<p>Bundler还提供了一个Bundler.require方法，该方法提供了比Bundler.setup更方便的特性，它将直接将Gemfile列举的依赖全部载入内存。关于使用Bundler.setup还是Bundler.require的讨论已经存在已久，无非就是Bundler.setup提供了一个妥协，使得程序可以滞后载入（Lazy Loading），从而减少不必要的加载，加快程序启动速度。而Bundler.require则主要是基于方便开发者（Programmer Friendly）的考量，它使开发者省去了大量的精力去显式地加载代码。</p>

<p>另外一个问题是有关Gemfile.lock文件的。我们是否需要check in这个文件到代码库里？这里的答案要度时而定。首先，我们知道Gemfile一般指明了一个依赖版本范围（或者没有），当我们运行bundle install的之后，生成的Gemfile.lock实际上是指明了每个依赖Gem的一个<strong>固定版本</strong>(在满足Gemfile指明的版本范围前提下)。</p>

<p>然后我们需要考虑这么一个convention，即我们开发Gem库的时候，我们总是希望我们的库能够和尽可能多版本的依赖Gem一同工作，而当我们开发应用的时候，我们往往希望我们依赖的Gem版本维持不变（因为此时的测试十分严格，将精确到Gem库的具体行为上），以保证我们的应用发布后十分稳定。</p>

<p>综合以上我们得出了结论，在开发Gem的时候，我们不添加Gemfile.lock到代码库，因为我们希望其他开发者通过bundle install绑定到依赖库尽可能多的版本，借此保证我们的Gem能够和更多的依赖库协同工作。而当我们开发应用之时，我们希望所有的开发者以及用户，严格的使用和我一样的依赖库版本，这使的每个人使用的依赖库行为严格一致，从而保证了应用的健壮性。</p>

<h2 id="bundlerrubygem---gem">当Bundler遇见RubyGem - Gem开发者需要知道的</h2>

<p>第一次使用bundler的时候，在为其精妙的设计而感叹的之际，一个疑问始终萦绕在我的心中：.gemspec和Gemfile这两个设计是不是过于冗余了？我们在开发Gem的时候，明明已经有.gemspec（RubyGem的一部分）指出依赖关系了，为什么此时Bundler还要鸡肋地设计一个Gemfile呢？</p>

<p>为了说明其原因，我们必须先回答一个基本问题：.gemspec和Gemfile分别是干嘛的？我们知道，.gemspec主要是用来描述Gem的元数据信息的，我们除了可以在此包含Gem的基本信息之外，还能够在此指出本Gem具体依赖于哪些其他Gem。不过，值得注意的是，这里仅仅是指出依赖关系，.gemspec并没有提供任何机制告诉我们，到哪里才能下载并部署这些被依赖的Gem。</p>

<p>.gemspec之所以缺少运行时的支持，那是因为下载、部署、以及载入并不是其设计之初的职责所在。这些问题是被后来者Bundler解决的。那么，既然搞清了其用途上的差异，我们又当如何解决其内容的冗余这个问题呢？答案很简单，在Gemfile文件中调用gemspec方法，它会自动告诉Bundler到同目录下查找.gemspec文件并载入其中指明的Gem依赖。</p>

<h2 id="rails">Rails的代码载入机制</h2>

<p>Rails开发者倾向于不使用显式的代码载入机制，为了实现这个目的，Rails使用了大量的自动载入机制。其一便是autoload，关于它的原理，以后我会撰文剖析。autoload主要用于载入Rails自己的组件，而对于依赖Gem的载入，Rails使用了Bundler.require机制。在Rails项目的文件config/application.rb负责实现此特性：</p>

<p><code>ruby
# Assets should be precompiled for production (so we don't need the gems loaded then)
Bundler.require(*Rails.groups(assets: %w(development test)))
</code></p>

<h2 id="section">写在最后</h2>

<p>代码载入看似很简单，只不过是将代码读入内存并且编译。可是，将这个需求放到真正的工程世界之后，情况便大不相同了。我们需要同时管理多个版本的组件，我们需要载入特定版本的组件，我们还需要解析某个组件的依赖……诸如此类的问题将代码载入这个话题无限扩大了，以至于Ruby后来才有了RubyGem、Bundler等一系列的工具、程序库来解决这些问题。我们要了解这个话题，不仅仅是一个技术人热爱技术的本性使然，更是为了在现实世界复杂的开发、运行环境里，更好的实现我们的目的（DO Things Right）。愿与诸君共勉！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[【译】Android位图颜色模式的问题]]></title>
    <link href="http://dahakawang.github.com/blog/2012/03/03/android-bitmap-color-mode/"/>
    <updated>2012-03-03T20:02:00+08:00</updated>
    <id>http://dahakawang.github.com/blog/2012/03/03/android-bitmap-color-mode</id>
    <content type="html"><![CDATA[<p>最近开始了android上的编程之旅，在了解2D图形编程时，令人蛋疼的发觉android上仅支持ARGB8888、ARGB4444、RGB565以及Alpha 8这么几种颜色模式，而不支持RGB888这种格式。原本以为即使不支持RGB888我用ARGB8888总行吧，但后来了解到，即使我在内存中用ARGB888颜色模型表示图像，在该图像拷贝到屏幕帧缓冲区的过程中，它也会变成RGB565颜色模式。我们知道，RGB565最多只能表示2^16=65536种图像，这对于RGB888所能表示的2^24=16777216种颜色来说显然在表现力上要略逊一筹。这集中表现在显示某些带有渐变效果的图片时，出现了一条条的颜色带，而不是原始的平滑的渐变效果。后来得知android使用了Dither(抖动)这种技术，以欺骗人类眼球的方式加以补偿。</p>

<p>当然，以这个问题为出发点，后来又引发了诸多问题，而这篇文章解决了我不少问题，特在这里翻译出来供大家分享之。</p>

<!-- more -->

<hr />

<p>在学习AvoidXfermode类的时候，我遇到了图片颜色不能正确显示的问题。我画了一个平滑渐变的色谱图片，然后用AvoidXfermode的Target功能将替换该图片里一种颜色替换为另外的颜色。但问题是，我想要替换的颜色并没有按照我所预想的一样被AvoidXfermode替换掉。原来，我的PNG图片被自动从24位的RGB888颜色模式转换为了16位的RGB565颜色模式，这使得图片中颜色的原始数值被改变了。</p>

<p>现在市面上几乎所有的设备都是16位色的屏幕，这意味着不管你在代码里使用什么颜色格式的图片，在某个时候它们都会被转化为16位图片，这样它们才能被显示在屏幕上。这种转换会占用处理器资源，会以时间和电池寿命的形式给用户造成损失。所以，我们并不期望这种转换在绘图时会发生，相反的，我们希望它还要在尽可能早的阶段里被完成。Android是一个智能的系统，在有些情况下Android会自动帮你完成这些转换工作，所以你并不需要担心这些问题。在大部分情况下，这个特性是相当棒的，它大大减少了开发者的工作量，也减少你的资源大小同时节省了处理器时间和电池寿命。但是，如果你希望在程序里将图片以一种指定的颜色格式处理，这种自动转化机制会让你头大的。幸运的是，我们有办法阻止自动转换的发生，让你的图片以你期望的颜色格式储存。</p>

<p>不过，既然这种自动转换既节省内存和处理器时间又保护电池寿命，那么为什么有人会不希望这种转换发生呢？Android程序中大部分的图片都只需要简单的载入并显示就行了。但是在一些教程以及我之前提到的例子中，我们需要在图片显示之前对它们做一些操作。为了得到最佳的效果，我们希望载入的图片在处理时尽能可能的保持最好的质量，因为在处理过程中过早的降低质量将对最终效果造成不良影响。</p>

<p>好了，这就是说在图片处理好之前，我们不希望被Android横插一脚。但是，Android系统将在什么时候替我们执行这些转换呢?答案是转换将在3个地方发生：</p>

<ul>
  <li>编译时图片资源被编译到软件包里去时</li>
  <li>当图片被从资源中载入为Bitmap时</li>
  <li>当图片被绘制时</li>
</ul>

<p>我们将看看这三类情况，并且了解如何避免这些转换。</p>

<h2 id="section">程序编译时</h2>

<p>当你在项目“res/drawable”文件夹下放置图片的时候，意味着你告诉Android：如果需要的话，在构建程序的时候将图片转换为16位图片。该转换发生的必要条件有哪些？无论你图片的原始格式是什么，如果你的图片没有alpha通道，在你的软件构建的时候Android会将它转换为本地16位色图。你有两种方法组织转换发生：</p>

<ul>
  <li>给图片添加alpha通道</li>
  <li>将图片放置到“res/raw”目录下而不是“res/drawable”</li>
</ul>

<p>通过给图片添加alpha通道，Android将不会尝试将图片转换为16位色图，这是因为RGB565颜色模式不带alpha通道。将一张带有alpha通道的图片转换为RGB565颜色格式会使半透明信息丢失，所以任何带有alpha通道的图片将被储存为32位的ARGB8888图片资源。通过将图片放置到“res/raw”目录下,我们告诉Android这个资源包含原始数据，它不应该在构建时更改。所以，对于我们放置到该目录下的任何图片都不会发生自动转换。但不幸的是，如果我们放在raw目录下的图片不带有alpha通道的话，这个方法还是有问题。这个问题在我们载入图片时显露了出来：</p>

<h2 id="section-1">图片载入时</h2>

<p>当使用BitmapFactory从你程序的资源中载入一张图片时，同样的自动转换机制会发生。如果你要载入的图片没有alpha通道，Android会将其转换为16位RGB565图片。不幸的是，即使我们将图片放置在“res/raw”目录下，这种转换依然会发生。根据在这个<a href="http://groups.google.com/group/android-developers/browse_thread/thread/8b1abdbe881f9f71">帖子</a>里一个叫<a href="http://www.curious-creature.org/">Romain Guy</a>的Android开发者所说，有一个解决之道：</p>

<blockquote>
  <p>“你需要做的就是将图片直接载入为ARGB888模式。当你调用
BitmapFactory.decode*()的某一个重载方法时，你能够指定一系列的
BitmapFactory.Option对象。你需要将Option对象中的inDither设置为false。这
样将会使BitmapFactory不去尝试将24位色图转换为16位色图。”</p>
</blockquote>

<p>当时，我发觉<strong>这个方法不起作用</strong>，至少在Android 1.6下都不起作用。传入一系列参数使得inDither为false的确使得图片不被抖动（Dither）处理，但是这种方法并不能阻止颜色模式的转换。图片依然会被转换成16位的RGB565，这将会使得转换后的渐变图片出现颜色条带的现象。</p>

<p>既然这个推荐的解决方案并不能满足我们的要求，那么在这个过程中唯一能保持你图片原貌的方法就是让你的图片带上alpha通道。当BitmapFactory发觉图片资源带有alpha通道，它便只能将图片解码为32位的ARGB888位图。</p>

<h2 id="section-2">绘制时</h2>

<p>假设我们有两张图片。图片A是ARGB888位图，图片B是RGB565位图。如果我们敬爱那个图片A绘制到B上，那么图片A将需要被转换为B的颜色格式。辛运的是，这种转换是由Canvas的drawBitmap方法替我们包办了。这对我们来说是个好消息，因为这正是我们想要的。在我们要释放位图资源的时候，我们已经完成调整和操作图片，并且图片将被转换和显示。然而，由于我们从32位转换为16位颜色深度，这将会造成图像的失真。为了减小失真对图片的影响，我们能够控制将图片从32位转换为16位的时机。当将一个高色深的图片绘制到第色深的图片上时，默认是不会进行抖动处理的。对于包含渐变的图片而言，这会使得图片出现众所周知的“色带”问题，这是非常难看的。为了克服这个问题，我们需要告诉Android我们想要对结果进行抖动处理。抖动是这么一种处理，它将原始颜色做出一些改变，以骗过我们的眼睛，让我们在低色深图片中以为自己看到了一个平滑的渐变。</p>

<p><strong>需要记住的是，当我们处理图片的时候，图片必须总是32位ARGB8888模式。</strong>只有当我们完成处理图片后，他们才应该被转换成16位色的图片。由于任何不带alpha通道的图片，再被BitmapFactory载入的时候将被转换为RGB565，不管它们是在”res/drawable”还是在”res/raw”目录下。而确保他们被解码为32色ARGB8888的唯一手段就是保证你的图片带有alpha通道。</p>

<h2 id="section-3">例子</h2>

<p>为了证明我所说，然我们做一个简单的测试。首先让我们写一个载入并以默认option显示两张图片的activity。两张图片都是平滑渐变的色谱，但是他们将被保存为不同的格式。第一张图将被保存为24位色RGB888的PNG图，第二张图片被保存为32位带有alpha通道的ARGB8888的PNG图片。两张图片有着完全一致的颜色数据，惟一的区别是一张带有alpha通道而另一张没有。保存两张图片，并把他们放置到你项目的”res/raw”目录下。然后，在你的activity中使用下列代码：</p>

<p>``` java
@Override
 public void onCreate(Bundle savedInstanceState) {
       super.onCreate(savedInstanceState);</p>

<pre><code>  // Load both of our images from our application's resources.
  Resources r = getResources();
  Bitmap resource= BitmapFactory.decodeResource(r, R.raw.spectrum_gray_nodither_;
  Bitmap resource= BitmapFactory.decodeResource(r, R.raw.spectrum_gray_nodither_;
 
  // Print some log statements to show what pixel format these images were decoded with.
  Log.d("FormatTest","Resource " + resourcegetConfig()); // Resource RGB_
  Log.d("FormatTest","Resource " + resourcegetConfig()); // Resource ARGB_8
</code></pre>

<p>// Create two image views to show these bitmaps in.
      ImageView image= new ImageView(this);
      ImageView image= new ImageView(this);
      imagesetImageBitmap(resource;
      imagesetImageBitmap(resource;</p>

<pre><code>  // Create a simple layout to show these two image views side-by-side.
  LayoutParams wrap = new LayoutParams(LayoutParams.WRAP_CONTENT, LayoutParams.WRAP_CONTENT);
  LayoutParams fill = new LayoutParams(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT);
  RelativeLayout.LayoutParams params= new RelativeLayout.LayoutParams(wrap);
  paramsaddRule(RelativeLayout.CENTER_VERTICAL);
  paramsaddRule(RelativeLayout.ALIGN_PARENT_LEFT);
  RelativeLayout.LayoutParams params= new RelativeLayout.LayoutParams(wrap);
  paramsaddRule(RelativeLayout.CENTER_VERTICAL);
  paramsaddRule(RelativeLayout.ALIGN_PARENT_RIGHT);
  RelativeLayout layout = new RelativeLayout(this);
  layout.addView(image params;
  layout.addView(image params;
  layout.setBackgroundColor(Color.BLACK);
 
  // Show this layout in our activity.
  setContentView(layout, fill);
</code></pre>

<p>}
```</p>

<p>编译此项目并将它部署到你的设备上查看结果。我们看到24位色图片在左边，为32位色图片在右边。但是等一下！32位的图片看上去有一些色带出现，然而24位图片看上去却很平滑。到底是怎么了？让我们仔细看看图片，我们能发现：</p>

<p><img src="/images/blogs/2012/original_image.png" alt="" /></p>

<p>仔细检查后，我们发觉24位图被抖动处理了，而32位色图没有。考虑到对于任何显示到Android设备屏幕的图片，都将被转换为16位色格式，所以这两张图都将发生这个转换。由于24位色图不带有alpha通道，并且它被放置在”res/raw”目录下，所以它将在我们载入activity中的资源时被自动转换为16位色图。我们能通过检查Logcat里的消息来验证这一点。我们从BitmapFactory里得到的Bitmap对象实际上是RGB565格式的，而BitmapFactory足够聪明会帮我们抖动处理图片。而我们带有alpha通道的的32位色图，则被载入为了ARGB8888位图。在该图片对应的ImageView被绘制到屏幕时，它将被转换为本地16位色格式。这里我们看到的是绘制时发生的转换不会进行抖动处理。让我们看一下，如果我们指明转换时进行抖动处理，情况是否会好一些。在上例中19行添加如下几行代码：</p>

<p><code>java
// Enable dithering when our 32-bit image gets drawn.
Drawable drawable32 = image32.getDrawable();
drawable32.setDither(true);
</code></p>

<p>编译后上传至设备然后查看结果：</p>

<p><img src="/images/blogs/2012/after_compiled.png" alt="" /></p>

<p>啊，好了。现在我们的32位图也已经被抖动处理好了。这里我们简单地告诉ImageView我们想要Bitmap被被绘制时进行抖动处理。不幸的是这将影响绘图速度，所以这并非一个理想的解决方案。但我们能够消除这个性能问题，通过在我们将图片送至ImageView之前预先进行抖动处理：</p>

<p>``` java
@Override
 public void onCreate(Bundle savedInstanceState) {
 super.onCreate(savedInstanceState);</p>

<p>// Load both of our images from our application’s resources.
 Resources r = getResources();
 Bitmap resource24 = BitmapFactory.decodeResource(r, R.raw.spectrum_gray_nodither<em>24);
 Bitmap resource32 = BitmapFactory.decodeResource(r, R.raw.spectrum_gray_nodither</em>32);</p>

<p>// Print some log statements to show what pixel format these images were decoded with.
 Log.d(“FormatTest”,”Resource24: “ + resource24.getConfig()); // Resource24: RGB<em>565
 Log.d(“FormatTest”,”Resource32: “ + resource32.getConfig()); // Resource32: ARGB</em>8888</p>

<p>// Save the dimensions of these images.
 int width = resource24.getWidth();
 int height = resource24.getHeight();</p>

<p>// Create a 16-bit RGB565 bitmap that we will draw our 32-bit image to with dithering.
 Bitmap final32 = Bitmap.createBitmap(width, height, Config.RGB_565);</p>

<p>// Create a new paint object we will use to draw our bitmap with. This is how we tell
 // Android that we want to dither the 32-bit image when it gets drawn to our 16-bit final
 // bitmap.
 Paint ditherPaint = new Paint();
 ditherPaint.setDither(true);</p>

<p>// Create a new canvas for our 16-bit final bitmap, and draw our 32-bit image to it with
 // the paint object we just created.
 Canvas canvas = new Canvas();
 canvas.setBitmap(final32);
 canvas.drawBitmap(resource32, 0, 0, ditherPaint);</p>

<p>// Create two image views to show these bitmaps in.
 ImageView image24 = new ImageView(this);
 ImageView image32 = new ImageView(this);
 image24.setImageBitmap(resource24);
 image32.setImageBitmap(final32);</p>

<p>// Create a simple layout to show these two image views side-by-side.
 LayoutParams wrap = new LayoutParams(LayoutParams.WRAP_CONTENT, LayoutParams.WRAP_CONTENT);
 LayoutParams fill = new LayoutParams(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT);
 RelativeLayout.LayoutParams params24 = new RelativeLayout.LayoutParams(wrap);
 params24.addRule(RelativeLayout.CENTER_VERTICAL);
 params24.addRule(RelativeLayout.ALIGN_PARENT_LEFT);
 RelativeLayout.LayoutParams params32 = new RelativeLayout.LayoutParams(wrap);
 params32.addRule(RelativeLayout.CENTER_VERTICAL);
 params32.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
 RelativeLayout layout = new RelativeLayout(this);
 layout.addView(image24, params24);
 layout.addView(image32, params32);
 layout.setBackgroundColor(Color.BLACK);</p>

<p>// Show this layout in our activity.
 setContentView(layout, fill);
 }
```</p>

<p>运行这段代码将会产生之前一样的效果，但是通过提前抖动处理，我们避免了性能瓶颈。如果你只是简单地载入和显示你的图片到你的activity一次，这种处理并不是必要的。但是如果需要频繁地绘制，则需要提前抖动处理以避免浪费处理时间和电池寿命。</p>

<p>这时候你可能会想了，为什么我们要做那么多额外的工作来确保我们的图片被解码为32位色图像，然而其结果却只是还要在我们绘图时做更多的工作来确保图片被抖动处理了呢？既然24位色被自动转换为了效果不错的16位色图而不需要你的任何干预，那么我们使用32位色图的理由是什么呢？实际上，对于上面的例子，我们还没有对这些位图做任何的处理和操作，所以被自动转换的24位色图片看上去和我们手动转换的32位色图片效果一样。他们最终都有着一样的像素数据。但是若是我们想要在显示之前对图片进行一些处理呢？咱们先试试看。在你的设备上运行下述代码：</p>

<p>``` java
@Override
 public void onCreate(Bundle savedInstanceState) {
 super.onCreate(savedInstanceState);</p>

<p>// Load both of our images from our application’s resources.
 Resources r = getResources();
 Bitmap resource24 = BitmapFactory.decodeResource(r, R.raw.spectrum_gray_nodither<em>24);
 Bitmap resource32 = BitmapFactory.decodeResource(r, R.raw.spectrum_gray_dithered</em>32);</p>

<p>Log.d(“FormatTest”,”Resource24: “ + resource24.getConfig()); // Resource24: RGB<em>565
 Log.d(“FormatTest”,”Resource32: “ + resource32.getConfig()); // Resource32: ARGB</em>8888</p>

<p>// Sadly, the images we have decoded from our resources are immutable. Since we want to
 // change them, we need to copy them into new mutable bitmaps, giving each of them the same
 // pixel format as their source.
 Bitmap bitmap24 = resource24.copy(resource24.getConfig(), true);
 Bitmap bitmap32 = resource32.copy(resource32.getConfig(), true);</p>

<p>// Save the dimensions of these images.
 int width = bitmap24.getWidth();
 int height = bitmap24.getHeight();</p>

<p>// Create a new paint object that we will use to manipulate our images. This will tell
 // Android that we want to replace any color in our image that is even remotely similar to
 // 0xFF307070 (a dark teal) with 0xFF000000 (black).
 Paint avoid1Paint = new Paint();
 avoid1Paint.setColor(0xFF000000);
 avoid1Paint.setXfermode(new AvoidXfermode(0xFF307070, 255, AvoidXfermode.Mode.TARGET));</p>

<p>// Make another paint object, but this one will replace any color that is similar to a
 // 0xFF00C000 (green) with 0xFF0070D0 (skyish blue) instead.
 Paint avoid2Paint = new Paint();
 avoid2Paint.setColor(0xFF0070D0);
 avoid2Paint.setXfermode(new AvoidXfermode(0xFF00C000, 245, AvoidXfermode.Mode.TARGET));</p>

<p>Paint fadePaint = new Paint();
 int[] fadeColors = {0x00000000, 0xFF000000, 0xFF000000, 0x00000000};
 fadePaint.setShader(new LinearGradient(0, 0, 0, height, fadeColors, null,
 LinearGradient.TileMode.CLAMP));
 fadePaint.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.DST_IN));</p>

<p>// Create a new canvas for our bitmaps, and draw a full-sized rectangle to each of them
 // which will apply the paint object we just created.
 Canvas canvas = new Canvas();
 canvas.setBitmap(bitmap24);
 canvas.drawRect(0, 0, width, height, avoid1Paint);
 canvas.drawRect(0, 0, width, height, avoid2Paint);
 canvas.drawRect(0, 0, width, height, fadePaint);
 canvas.setBitmap(bitmap32);
 canvas.drawRect(0, 0, width, height, avoid1Paint);
 canvas.drawRect(0, 0, width, height, avoid2Paint);
 canvas.drawRect(0, 0, width, height, fadePaint);</p>

<p>// Create a 16-bit RGB565 bitmap that we will draw our 32-bit image to with dithering. We
 // only need to do this for our 32-bit image, and not our 24-bit image, because it is
 // already in the RGB565 format.
 Bitmap final32 = Bitmap.createBitmap(width, height, Bitmap.Config.RGB_565);</p>

<p>// Create a new paint object that we will use to draw our bitmap with. This is how we tell
 // Android that we want to dither the 32-bit image when it gets drawn to our 16-bit final
 // bitmap.
 Paint ditherPaint = new Paint();
 ditherPaint.setDither(true);</p>

<p>// Using our canvas from above, draw our 32-bit image to it with the paint object we just
 // created.
 canvas.setBitmap(final32);
 canvas.drawBitmap(bitmap32, 0, 0, ditherPaint);</p>

<p>// Create two image views to show these bitmaps in.
 ImageView image24 = new ImageView(this);
 ImageView image32 = new ImageView(this);
 image24.setImageBitmap(bitmap24);
 image32.setImageBitmap(final32);</p>

<p>// Create a simple layout to show these two image views side-by-side.
 LayoutParams wrap = new LayoutParams(LayoutParams.WRAP_CONTENT, LayoutParams.WRAP_CONTENT);
 LayoutParams fill = new LayoutParams(LayoutParams.FILL_PARENT, LayoutParams.FILL_PARENT);
 RelativeLayout.LayoutParams params24 = new RelativeLayout.LayoutParams(wrap);
 params24.addRule(RelativeLayout.CENTER_VERTICAL);
 params24.addRule(RelativeLayout.ALIGN_PARENT_LEFT);
 RelativeLayout.LayoutParams params32 = new RelativeLayout.LayoutParams(wrap);
 params32.addRule(RelativeLayout.CENTER_VERTICAL);
 params32.addRule(RelativeLayout.ALIGN_PARENT_RIGHT);
 RelativeLayout layout = new RelativeLayout(this);
 layout.addView(image24, params24);
 layout.addView(image32, params32);
 layout.setBackgroundColor(Color.BLACK);</p>

<p>// Show this layout in our activity.
 setContentView(layout, fill);
 }
```</p>

<p>这里我们载入了和之前例子一样的图片，但我们现在使用Android内置的图形函数对他们预先进行了一些处理，而不是直接将它们添加到ImageView中显示。我们在显示两张图片前分别将它们都使用了三个不同的滤镜进行处理。要是你不明白23-52行代码是干嘛的，别担心，我会在以后的文章中详尽的介绍它们。而对于现在而言，你只需要知道我们的原始图片在运行时被我们的程序进行了巨大的变换。下图是最终的效果：</p>

<p><img src="/images/blogs/2012/final_image.png" alt="" /></p>

<p>正如你所看到的，在经过了许多操作后，24位色图有了巨大的失真，而32位色图的效果则依然很不错。除了”条带”和失真，你可以发现24位色图的颜色根本都不正确。那么，为什么24位色图会出现这种现象而32位色图却没有呢？原因就在于24位色图被Android自动转换为了RGB565格式图像。一张16位色图片仅能够显示65,535种不同颜色，而32位色图却能够显示16,777,215种颜色，还带有255级半透明效果。这意味着当我们处理16位色图时，处理过后的颜色不能够被16位色所支持的65,535种颜色精确地表示出来。所以处理后的颜色被截取到了最临近相似的颜色值去了。每次我们对图片进行操作时，这种截取都会发生，所以图片将变得更加不精确。而当时用32位色时，这种现象虽然依然会有，但是由于有着将近17兆的颜色可以表示，这种副作用对于大部分程序来说将可以被忽略。</p>

<p>我希望我的这篇文章能帮到各位。我希望各位能从我的文章中学会的主要思想是：</p>

<ol>
  <li>要意识到Android的自动图片转换和抖动处理机制。当事情不照你所想发展时，知道Android是如何储存、载入以及绘制你的图像的话将大大减轻你的头痛。</li>
  <li>如果你要对你的图像被载入后进行任何的处理，确保你的图片是ARGB8888格式的。</li>
  <li>通过使用某种图形处理软件将你的图像保存为32位带alpha通道的PNG图片，你可以强制这张图片被载入为32位色。</li>
  <li>当你处理完你的32位色图片后，记得启用抖动处理后再将该图片转换为16位RGB565色图。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Condition Variable为什么需要一个Mutex的思考]]></title>
    <link href="http://dahakawang.github.com/blog/2012/02/19/why-condition-variable-need-a-mutex/"/>
    <updated>2012-02-19T23:37:00+08:00</updated>
    <id>http://dahakawang.github.com/blog/2012/02/19/why-condition-variable-need-a-mutex</id>
    <content type="html"><![CDATA[<ol>
  <li>Linux下：</li>
</ol>

<p><code>c
pthread_mutex_lock(&amp;mutex);
pthread_cond_wait(&amp;cond, &amp;mutex);
doSomething();
pthread_mutex_unlock(&amp;mutex);
</code></p>

<!-- more -->

<ol>
  <li>java里：</li>
</ol>

<p><code>java
synchronized(this){
    wait();
    doSomething();
}
</code></p>

<ol>
  <li>C#里：</li>
</ol>

<p><code>c#
monitor.Enter();
monitor.Wait();
doSomething();
monitor.Exit();
</code></p>

<ol>
  <li>使用Win32API</li>
</ol>

<p><code>c
EnterCriticalSection (&amp;cs);
SleepConditionVariableCS (&amp;cond, &amp;cs, INFINITE);
doSomething();
LeaveCriticalSection (&amp;cs);
</code></p>

<p>不难看到，不管是哪种语言，不论使用什么程序库，无论在windows下亦或是Linux下，condition variable这个东西的用法似乎都是固定的：必须和一把锁搭配使用。</p>

<p>可是，问题是为什么这些库、框架、系统的设计者，在设计这套机制的时候，非要让我们好死不死再和一把锁一块儿使用呢？做这种费力不讨好的事儿，到底是因为历史原因，还是另有深意呢？</p>

<p>为了回答这个问题，首先考虑这么一个生产者消费者的场景。生产者会生产数据将其放到dataHandler对象中，然后向消费者发送一条消息。消费者也有dataHandler示例的句柄，并且在接收到生产者的消息后，它将通过dataHandler.getData()来获取数据。假设这个世界上的condition variable全是没有mutex机制的，则消费者的实现代码可能是这样的：</p>

<p><code>c
if(!bDataReady){
     pthread_cond_wait(&amp;sigDataReady); //根据假设，我们现在不需要锁了
}
data = dataHandler.getData();
dataHandler.releaseData();
</code></p>

<p>代码的逻辑十分简单。但是，现在我们考虑一下，如果有以下执行顺序：</p>

<ul>
  <li>消费者：检查bDataReady不为真</li>
  <li>生产者：设置bDataReady为true</li>
  <li>生产者：发送消息</li>
  <li>消费者：等待condition variable</li>
</ul>

<p>这时，虽然生产者通知了资源的可用，但由于这时候消费者尚未开始等待消息，也就没能接收到这个消息，于是只能在消息消失后无尽地等待下去。另一方面，由于消费者一直的等待，导致资源不被消费，在糟糕的情况下生产者会等待消费者消费完毕。于是乎，死锁发生了。</p>

<p>思考一下，为什么会发生死锁呢？其本质的原因在于生产者、消费者的行为没有保证原子性(Atomic)。这时候，我们要问了，既然pthread_cond_wait是系统级别的同步互斥工具，它怎么会不能保证原子性？当然，我并非指这个意义上的原子性。我们首先要知道condition variable的设计意图，实际上condition variable描述这么一种情景：在这个情境中，有一个人在等待一个特定事件，而另一个人会在该事件发生时告知前者。但是，condition variable本身只实现这么一种机制，它并不指出到底是什么事件发生了。因此，往往我们在等待成功，知道有事件发生的话，还需要额外代码来判断是哪个事件。注意，这就是整个问题的关键点：</p>

<p>实际上我们在使用condition variable时，不仅要通condition variable实现通知和被通知，还要自行实现通知和被通知前后所必要的判断、处理等业务逻辑，这才是condition variable的使用模型。知道这个后，我们就能理解为什么上面的情景会出问题了。原因在于消费者的基本行为没有确保原子性，它的判断和等待被分隔了。</p>

<p>我们当然可以争辩道，即使不通过和mutex合作，我们一样能使用这个假想的condition variable很好的完成功能。是的，我承认作为程序员你可以足够聪明和小心，以至于你实现的版本没有我上面这段代码的问题。但是，这难道不和你去跟设计mutex的人争辩说你明明可以自己通过精心设计实现互斥，根本不用mutex横插一脚这件事一样愚蠢且毫无意义么？谁也不能阻止你选择使用自己的办法，但是问题的关键是，我们需要一种有经过理论证明研究过的可靠的、统一的方法，因为软件开发在大部分情况下是一门工程，而不是一门任你发挥的艺术。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World程序背后的故事解密（二）—— 程序之生]]></title>
    <link href="http://dahakawang.github.com/blog/2011/10/19/how-a-program-is-born/"/>
    <updated>2011-10-19T16:03:00+08:00</updated>
    <id>http://dahakawang.github.com/blog/2011/10/19/how-a-program-is-born</id>
    <content type="html"><![CDATA[<p>近几个月实在是太忙了，偶然想起来博客上一看，离上次写文章居然过了两个月有余，于是手痒痒想加把劲，再码点儿技术文上来^_^</p>

<p>这个系列是为了挖掘出一个简单的类似Hello World程序隐藏在CRT之下的复杂性，因此在上次分析了“编译器选项和CRT”之后，今天我想再来简单分析一下从程序进程建立直到程序运行到C/C++入口函数处发生的那点儿事儿。</p>

<!-- more -->

<p>我们知道，在Windows下一个进程是使用CreateProcess函数创建的，这个函数调用的成功，标志着有一个程序被加载至内存并准备开始运行了。系统在建立进程时，会完成给进程分配资源，初始化进程的内存空间，初始化进程内核对象，初始化进程环境快（PEB），加载PE映像文件，初始化全局堆，载入DLL等等工作，但是这些工作完成后却并不代表我们的程序已经开始执行了。这是因为进程本身是有“惰性”的，它不会主动执行代码，所以操作系统这时候会建立我们程序的第一个线程，而我们的代码将从这个线程来开始执行。</p>

<p>既然我们讨论“开始执行”，那么本文将不会涉及CreateProcess的原理以及系统建立进程的细节。我们将从线程的建立开始，来讨论我们的主题。</p>

<p>我们且不谈系统提供的给我们使用的CreateThread等函数，首先我们需要知道的是实际上一个线程的建立最终是由NtCreateThreadEx函数实现的，而这个函数则是将58作为调用号传入EAX然后直接使用sysenter指令陷入内核，从而使得线程能够最终建立。NtCreateThreadEx是一个没有被微软公布的函数，由ntdll.dll文件导出。如果你有兴趣可以去网上搜索该函数的原型，但注意由于它并是不公开的函数，所以网上所述的原型不一定正确，并且微软也不会保证今后这个接口不会改变。</p>

<p>内核在接收到新建线程的请求后就会替我们着手新建一个线程，并且为该线程初始化一些参数（包括TEB等），最终将线程的入口设置为RtlUserThreadStart函数，该函数是由ntdll.dll导出的。RtlUserThreadStart的主要工作就是建立SHE的异常处理函数链，它有两个参数，其中一个是用户之前指定的线程入口函数，另一个是传给该入口的参数。注意虽然RtlUserThreadStart有两个参数，但这并不意味着曾经有人调用过它并且给它传参了，这两个参数实际上这是操作系统硬性写入的两个值。我们必须知道，实际上RtlUserThreadStart的执行只是因为操作系统把该线程EIP硬性设置到了RtlUserThreadStart的入口处而已。</p>

<p>RtlUserThreadStart会调用BaseThreadInitThunk函数，这个函数是由kernel.dll导出的，它主要将用户指定的参数压栈，接着就直接调用用户指定的线程入口函数了。</p>

<p>至此，一个线程全面建立！</p>

<p>当然，如果这个线程是主线程的话，情况有些不同。因为这时候BaseThreadInitThunk调用的可还不会是你的main或WinMain函数，它将调用PE文件中指定的入口函数，如果是VC编译的程序这个入口将是mainCRTStartup函数。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Visual C++增量链接以及.textbss]]></title>
    <link href="http://dahakawang.github.com/blog/2011/08/01/about-vc-increamental-linking-and-textbss/"/>
    <updated>2011-08-01T22:08:00+08:00</updated>
    <id>http://dahakawang.github.com/blog/2011/08/01/about-vc-increamental-linking-and-textbss</id>
    <content type="html"><![CDATA[<p>好的，文接上回，本文我就来讲讲微软link.exe连接器的Incremental Liking这个特性。当然这个其实不是微软linker独有的特性，很多链接器都有这个特性，这个特性实际上是为了提高链接速度的。</p>

<p>想象一下这个场景，我写了两个函数foo()和bar()，其中foo()在0x400100处而bar()紧接着保存在0x400200处。现在我将foo()改写了一下，添加了一些perfect的功能，然后编译了新的代码。不过现在的麻烦是foo()不可避免的变大了，他现在需要200h字节来保存了。那么链接器该怎么办？</p>

<!-- more -->

<p>一般的思考是——重新洗牌，将现有的编译好的exe删除了，然后重新布局所有的函数，也即是说bar()函数向后挪动0x100h字节的位置，给foo()腾出空间来。然后之后所有的函数都需要重新定位……对于大型软件来说这个处理时间开销是痛苦的，但作为程序员我们却不能避免需要不断的调试改代码，不断地重复这个耗时的工作。</p>

<p>不过我们现在并不需要给客户最终的发行代码，我们只是想要尽快地将程序的bug改掉然后去休息而已！于是，Incremental Linking出现了！它的原理如下：</p>

<p><img src="/images/blogs/2012/increamental_linking.gif" alt="" /></p>

<p>现在连接器不会将所有函数紧挨着放在一块儿了，他们会在函数之间加上padding，这个时候函数要想添几句指令就有余地了。只要我们的改动不大，没有超过padding的范围连接器就不需要重新洗牌，这大大提高了链接的速度。</p>

<p>先别高兴，加入我们的改动很大，以至于超过padding能够搞定的范围怎么办？如上图，我们还会在整个section末尾设置一个较大的padding（当然具体在哪里要看实现，比如我这图是从GCC那里搞得，说的就是ld.exe的行为方式），这时候就可以将这个函数搬到这里来了。但有个毁灭性的问题——所有调用我这个函数的函数都必须重定位他们的call指令啊！</p>

<p>为了解决这个问题，我们引入了一个ILT表（Incremental Linking Table），这个表是放在.text区域中的（我在IDA中观察得知）。它的原理是什么呢？我们来看：</p>

<p>``` nasm
;之前我们都是直接调用函数
   call foo</p>

<p>;现在我们来点小把戏
   call foo_stub</p>

<p>foo_stub:
   jmp foo
```</p>

<p>我们现在不直接调用函数，而是call到一个包含jmp指令的地方，然后由这个指令将我们的程度带往foo()函数的实现去。现在如果我们将foo()的实现改动过大后，linker直接将foo()移动了，然后只需要修改这个jmp指令就行了。可以看到，这种实现方式开销是O(1)。然后当很多个函数都用这种方式时，就形成了一个有jmp指令构成的表——这就是ILT表啦。</p>

<p>有兴趣的童鞋可以做下实验，在VS2010编译一次代码，然后用IDA或者W32Dasm之类的软件可以看到两个函数之间间隔了不少距离，而这些间隔就是我们所谓padding。padding被填充以<strong>0xCCh</strong>的数据。熟悉win32汇编的朋友这时候该笑而不语了，是的，这个值就是指令<strong>INT 3</strong>。在WIndows下，执行这个指令会引发一个异常，然后程序会被终止或是回到调试器去，这当然是出于安全性考虑的。这之后如果你在前一个函数加几句话，编译后可以看到两个函数位置不变，但函数间的padding变小了。</p>

<h2 id="textbss">和.textbss的关系</h2>

<p>之前有篇我讨论了PE常见的section，里面提到了这个节，下面我就详细介绍一下它的作用。</p>

<p>首先Incremental Linking作用不仅仅是在于减少我们重新连接程序所需要的时间，他还是我们调试时能够动态改动代码的前提。不知你还记得不，在那个炎热的夏天，你正汗流浃背地在没有空调的部屋里调试C代码（咳，说远了……）你直接修改了代码，然后VS直接在调试的时候将你的改动反映到程序里去了。这就是VS在Debug模式时动态编译代码的功能。</p>

<p>实际上这个功能是基于Incremental Linking机制的，而且是使用的Incremental Linking的第二套方案——直接找个大的地儿把修改的函数挪过去。</p>

<p>但是和.textbss有啥关系？</p>

<p>首先我们看到，.textbss有关键字bss，这就说明实际上这个节没有占据实际的硬盘空间。然后text关键字告诉我们这里段是包含代码的，另外用工具查知这个段有可执行属性更是印证了这个观点。没有代码，那要这个节有啥用呢？</p>

<p>你想到了么？是的，在VS动态编译的时候，他直接将被修改的函数放到了.textbss节里，然后修改了对应的ILT表项，是他指向这个位置。</p>

<p>说是简单，但实际上这个过程还个细节需要注意——你把我的函数挪地儿了，要是我正在执行这个函数怎么办？实际上，在改了ILT之后立刻会做的，就是检查当前程序所有线程的TIB，如果他们的EIP指向老的函数（它们正在执行老版本函数），我们就修改EIP使其指向新版本函数的对应位置。当然，这实际上暗示了，这个工作非要在调试程序的帮助下不可了。注意动态编译的功能只在Debug版本程序下有效,Release版本是不行的，因为Release版本默认禁用Incremental Linking。</p>

<p>下面是实验时间，以验证我的观点：</p>

<p>我就用手头上的程序来测试。有函数CheckValidPE()，它的RVA是0x12490h（你可理解为内存地址）。我的程序地址空间部分如下：</p>

<table>
  <tbody>
    <tr>
      <td>Section　　　</td>
      <td>　　　  RVA　　　</td>
      <td>　　　Size</td>
    </tr>
    <tr>
      <td>.textbss　　　</td>
      <td>　　　1000h　　　</td>
      <td>　　10000h</td>
    </tr>
    <tr>
      <td>.text　　　　　</td>
      <td>　　 11000h　　</td>
      <td>　　　7000h</td>
    </tr>
  </tbody>
</table>

<p>可以看到这两个函数实际上是位于.text节内的。我在CheckValidPE()上下个断，可以看到：</p>

<p><code>nasm
 bool PEAnalyser::checkValidPE()
{
00D92490  push        ebp
00D92491  mov         ebp,esp
00D92493  sub         esp,0FCh
00D92499  push        ebx
00D9249A  push        esi
00D9249B  push        edi
00D9249C  push        ecx
......
</code></p>

<p>从这里我发觉了VS貌似从来都是随机装载PE映像的ImageBase位置的，搞得我之前一次实验满心欢喜用常用的0x400000h为基址换算了所有的RVA~~T_T。。。</p>

<p>我之前说了CheckValidPE()的RVA是0x12490h，这里的绝对地址是0x00D92490h，我们用0x00D92490h-0x12490h = 0xD80000h，得到两个的差值。哈哈，看来这次的映像基址被射到了0xD80000h。</p>

<p>我回到VS源代码视图上，对代码稍作粉饰，嗯，然后它发生了！！！</p>

<p><code>nasm
bool PEAnalyser::checkValidPE()
{
00D81000  push        ebp
00D81001  mov         ebp,esp
00D81003  sub         esp,0FCh
00D81009  push        ebx
00D8100A  push        esi
00D8100B  push        edi 
00D8100C  push        ecx
00D8100D  lea         edi,[ebp-0FCh]
00D81013  mov         ecx,3Fh
00D81018  mov         eax,0CCCCCCCCh
00D8101D  rep stos    dword ptr es:[edi]
.....
</code></p>

<p>注意看函数变到这个地址来了！！而且VS的调试程序指针也确实说明EIP被更改了。</p>

<p>我们来算一下，看看这个地址在哪里？用这里新的函数起始地址减去我们之前计算的的基址得到RVA = 0xD81000h - 0xD80000h = 0x1000h</p>

<p>回去查一下我的内存地址空间，RVA为0x1000h正是位于.textbss节的起始位置。看来我的猜测是正确的。</p>

<h2 id="section">小结</h2>

<p>小结一下，关于Incremental Linking，由于他的机制所致，势必带来程序体积的臃肿以及执行的低效，但是由于我们只是在Debug程序是使用，所以问题不大。另外VS默认是在Debug是开启Incremental Linking而Release模式关闭这个特性的。这说明在Release时，我们不能够动态的改动代码了。</p>

<p>另外注意Incremental Linking是和/LTCG 选项不兼容的，你不能同时开启Incremental Linking和Link Time Code Generation，从这个角度讲，使用Incremental Linking进一步会造成程序执行效率下降。所以，我们应该在发布程序时，注意避免带上这个特性。</p>
]]></content>
  </entry>
  
</feed>
